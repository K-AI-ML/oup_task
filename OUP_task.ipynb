{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Task details\n",
        "\n",
        "This task should not take you more than 3-4 hours. You are a language engineer working on a lexicon delivery for the Kazakh language. You are provided with corpus data (a corpus of sentences) where each sentence has been tokenised, and each token has been lemmatized and annotated with additional information including part-of-speech tags and morphological features.\n",
        "\n",
        "A short sample of the corpus data is provided with the link below: sample_parsed_sentences.json\n",
        "\n",
        "Your task is to take this input and process it using Python. You should use data classes (you can use Pydantic if you are familiar with this package) to produce the output. The output should be a JSON file and should contain the following information:\n",
        "\n",
        "· An entry per lemma for all lemmas in the sample_parsed_sentences file\n",
        "\n",
        "· The part of speech label and all inflection information per lemma\n",
        "\n",
        "· A total frequency count for each lemma\n",
        "\n",
        "· A total frequency count for each wordform per lemma\n",
        "\n",
        "Please share your code in a public git repository. Please provide the following additional details along with your submission:\n",
        "\n",
        "1. Any documentation you feel necessary to understand and run your solution\n",
        "\n",
        "2. How would you foresee your solution to run in production environment (you do not need to build the actual pipeline). Can you mention any cloud services that you are familiar with, that can be used to run your solution?\n",
        "\n",
        "3. Any other details you would like to share with us"
      ],
      "metadata": {
        "id": "v73jVT5cllax"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ijson"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTFgyocAuOLG",
        "outputId": "e2b1764a-38b3-4141-d07f-fa89281fa85d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ijson\n",
            "  Downloading ijson-3.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (111 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.8/111.8 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ijson\n",
            "Successfully installed ijson-3.2.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "sh_bGt0clc9B"
      },
      "outputs": [],
      "source": [
        "from pydantic import BaseModel, ValidationError\n",
        "from typing import Optional\n",
        "import ijson\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class WordForm(BaseModel):\n",
        "    text: str\n",
        "\n",
        "class Lemma(BaseModel):\n",
        "    lemma: str\n",
        "\n",
        "class Feats(BaseModel):\n",
        "    pos: str\n",
        "    pos_finegrained: str\n",
        "    feats: Optional[str]"
      ],
      "metadata": {
        "id": "UD7L-VsippTM"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lemmas = {}\n",
        "\n",
        "input_file_path = 'sample_parsed_sentences.json'\n",
        "with open(input_file_path, \"rb\") as f:\n",
        "    for k, v in ijson.kvitems(f, 'sentences.item'):\n",
        "        if k == 'tokens':\n",
        "            for obj in v:\n",
        "                try:\n",
        "                    lemma_obj = Lemma(**obj)\n",
        "                    wordform_obj = WordForm(**obj)\n",
        "                    feats_obj = Feats(**obj)\n",
        "\n",
        "                except ValidationError as e:\n",
        "                    print(e)\n",
        "\n",
        "                lemma = lemma_obj.dict().get('lemma')\n",
        "\n",
        "                if lemma not in lemmas:\n",
        "                    lemmas[lemma] = feats_obj.dict()\n",
        "                    lemmas[lemma].update({'lemma_total_frequency_count': 1})\n",
        "                    lemmas[lemma]['wordform_total_frequency_count'] = {}\n",
        "                else:\n",
        "                    lemmas[lemma]['lemma_total_frequency_count'] +=1\n",
        "\n",
        "                wordform = wordform_obj.dict().get('text')\n",
        "                if wordform not in lemmas[lemma]['wordform_total_frequency_count']:\n",
        "                    lemmas[lemma]['wordform_total_frequency_count'][wordform] = 1\n",
        "                else:\n",
        "                    lemmas[lemma]['wordform_total_frequency_count'][wordform] += 1\n",
        "\n",
        "lemmas_obj = json.dumps(lemmas, indent=4, ensure_ascii=False)\n",
        "with open(\"lemmas_out.json\", \"w\") as outfile:\n",
        "    outfile.write(lemmas_obj)"
      ],
      "metadata": {
        "id": "T6EbEQxo1pa_"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notes:\n",
        "\n",
        "`input_file_path` variable should be changed to location of file in local directory. Using ijson to stream potentially large json files rather than load into memory. Parrelization alongside other distributed methods can significantly reduce processing times.\n",
        "\n",
        "Running on cloud:\n",
        "\n",
        "To run on cloud server, for example Google App Engine, the application can be accessed using an API endpoint. This endpoint can be interfaced using REST API to request and send input and output data respectively."
      ],
      "metadata": {
        "id": "niJ-cwefBecw"
      }
    }
  ]
}